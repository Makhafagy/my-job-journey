# üöÄ My Job Journey: An Automated Application Tracker

This project provides a suite of Python scripts to automate the tedious process of finding, filtering, and analyzing new-graduate software engineering job applications. It transforms the job hunt from a chaotic spreadsheet nightmare into a streamlined, data-driven workflow.

This system scrapes the latest job postings, filters them against your application history and preferences, and generates performance reports on your application funnel‚Äîshowing you exactly how your efforts are translating into interviews and offers.

---

## ‚ú® Key Features

* **Automated Scraping:** Pulls the latest new-grad software engineering roles from the SimplifyJobs `New-Grad-Positions` GitHub repository.
* **Intelligent Filtering:** Automatically filters scraped jobs to show only the most relevant opportunities:
    * **Location:** Keeps only US-based roles.
    * **Age:** Only shows jobs posted within the last 7 days.
    * **History:** Hides jobs you've already applied to, so you never apply twice.
* **Centralized Tracking:** Uses a master CSV file as a single source of truth for every application's status, from initial application to final offer.
* **Performance Analytics:** Includes a powerful analysis script that reads your master file and calculates key performance indicators (KPIs), including:
    * Interview Rate (%)
    * Offer Rate (%)
    * Ghosted Rate (Pending) (%)

---

## ‚öôÔ∏è Project Components

The project is composed of several scripts and key data files that work together.

### The Scripts

* **`pull_apply_links.py`**: The main scraper. It fetches all active job listings from the source and performs initial filtering for age and location.
* **`filter_jobs.py`**: Cross-references the newly scraped jobs against your master application list and removes any you have already applied to.
* **`prepare_tracker.py`**: A one-time setup script that adds the necessary tracking columns (`Date Applied`, `Status`) to your master CSV file.
* **`detailed_analysis.py`**: The analytics engine. It reads your master file, calculates your application funnel metrics, and saves a performance report.

### The Data Files (Ignored by Git)

* **`new_grad_swe_apply_links.csv`**: A temporary file containing the fresh, filtered list of jobs you should apply to. This file is overwritten each time you run the workflow.
* **`new_grad_swe_apply_links_applying.csv`**: **Your master tracking file.** This is the most important file in the project and acts as your personal application database. It is intentionally ignored by Git to keep your data private.
* **`application_analysis.csv`**: The output report generated by the analysis script, containing your key metrics.

---

## üìà How to Use: A Step-by-Step Guide

Follow this guide to get set up and use the tracker in your daily job search.

### Part 1: Initial Setup (One-Time Only)

1.  **Install Prerequisites:** Make sure you have Python 3 installed. Then, install the required libraries from your terminal:
    ```bash
    pip install requests beautifulsoup4
    ```
2.  **Create Your Master File:** Create a new, blank CSV file in the project folder and name it exactly `new_grad_swe_apply_links_applying.csv`.
3.  **Add Headers to Master File:** Open the blank CSV and add the following headers in the first row:
    `flags,company,title,location,apply_url,age,no_sponsorship,requires_us_citizenship,faang_plus,closed,advanced_degree,Applied`
4.  **Prepare the Tracker:** Run the `prepare_tracker.py` script. This will automatically add the `Date Applied` and `Status` columns to your master file.
    ```bash
    python prepare_tracker.py
    ```

### Part 2: The Daily Routine

Perform these steps whenever you want to find and apply for new jobs.

1.  **Scrape & Filter New Jobs:** Run these two scripts in order.
    ```bash
    # Step A: Get the latest jobs from GitHub
    python pull_apply_links.py

    # Step B: Remove jobs you've already applied to
    python filter_jobs.py
    ```
    The `new_grad_swe_apply_links.csv` file now contains your up-to-date list of jobs to apply for.

2.  **Apply & Update Your Master File:**
    * Open `new_grad_swe_apply_links.csv` to see the new jobs.
    * As you apply to each job, copy its row and paste it into your master file, `new_grad_swe_apply_links_applying.csv`.
    * In the master file, update the new row:
        * Set the **`Applied`** column to **`TRUE`**.
        * Fill in the **`Date Applied`** column.
        * Set the **`Status`** column to **`Applied`**.

3.  **Track Your Progress:**
    * As you hear back from companies, update the **`Status`** column in your master file with values like `Interview`, `Offer`, `Rejected`, or `Ghosted`.
    * Run the analysis script at any time to see your updated stats.
    ```bash
    python detailed_analysis.py
    ```
    This will generate the `application_analysis.csv` report with your latest funnel metrics.
