# 🚀 An Automated Application Tracker

This project provides a suite of Python and Google Apps scripts to automate the process of finding, filtering, and analyzing new-graduate software engineering job applications. It transforms the job hunt from a chaotic spreadsheet nightmare into a streamlined, data-driven workflow.

This system scrapes the latest job postings, filters them against your application history, and generates performance reports on your entire application funnel—showing you exactly how your efforts are translating into interviews and offers over time.

---

## ✨ Key Features

* **Automated Scraping:** Pulls the latest new-grad software engineering roles from the SimplifyJobs `New-Grad-Positions` GitHub repository.
* **Intelligent Filtering:** Automatically filters scraped jobs to show only the most relevant opportunities based on location (US-only), age (posted < 7 days), and your complete application history.
* **Google Sheets Integration:** Includes a Google Apps Script to seamlessly manage your tracking sheet, automatically adding checkboxes and highlighting applied-to jobs.
* **Historical Analysis:** Aggregates data from your current application file and an archive of past files (`past_applied_data`) to provide a complete, all-time view of your job search performance.
* **Performance Analytics:** The analysis script calculates key performance indicators (KPIs), including your Interview Rate, Offer Rate, and Ghosted Rate.

---

## ⚙️ Project Components

The project is composed of several scripts and key data files that work together.

### The Scripts

* **`pull_apply_links.py`**: The main scraper that fetches all active job listings and performs initial filtering.
* **`filter_jobs.py`**: Cross-references the newly scraped jobs against your entire application history (current and past files) and removes any you have already applied to.
* **`prepare_tracker.py`**: A one-time setup script that adds the necessary tracking columns (`Date Applied`, `Status`) to a new master CSV file.
* **`detailed_analysis.py`**: The analytics engine. It reads your current and past application files, calculates your funnel metrics, and saves a performance report.
* **`count_applications.py`**: A simpler analysis script that provides a quick count and company breakdown of your total applications over time.
* **`google_sheets_tracker.gs`**: The Google Apps Script code used to manage your tracking spreadsheet.

### The Data Files & Folders (Ignored by Git)

* **`new_grad_swe_apply_links.csv`**: A temporary file containing the fresh, filtered list of jobs to import into Google Sheets.
* **`new_grad_swe_apply_links_applying.csv`**: Your **current** master tracking file, downloaded from Google Sheets.
* **`past_applied_data/`**: A folder containing all your **archived** application files from previous sessions.
* **`application_analysis.csv`**: The output report generated by the analysis script.

---

## 📈 How to Use: A Step-by-Step Guide

### Part 1: Initial Setup (One-Time Only)

1.  **Install Prerequisites:** Make sure you have Python 3 installed. Then, install the required libraries from your terminal:
    ```bash
    pip install requests beautifulsoup4
    ```
2.  **Create Your Folders:** Make sure you have a `past_applied_data` folder in your project directory.
3.  **Set Up Google Sheets:**
    * Create a new Google Sheet.
    * Go to `Extensions > Apps Script`.
    * Delete any placeholder code and paste the entire content from the `google_sheets_tracker.gs` file into the editor.
    * Save the script project. You will now have an "Apply Tracker" menu in this sheet.

### Part 2: The Main Workflow

Perform these steps whenever you want to find and apply for new jobs.

1.  **Find New Jobs:** Run this script in your project folder to generate an up-to-date list of job openings.
    ```bash
    # Get the latest jobs scraped from simplify GitHub (default: up to 7 days of posting age)
    python pull_apply_links.py

    # Use the optional --days argument to control how far back the job search goes. If the below is omitted, it'll scrape postings up to 3 days of posting age.
    python pull_apply_links.py --days 3
    ```

2.  **Track in Google Sheets:**
    * **Import Data:** In your Google Sheet, go to `File > Import` and upload the newly generated `new_grad_swe_apply_links.csv` file. Select "Replace current sheet".
    * **Prepare Tracker:** Use your custom `Apply Tracker > Add Applied Column` menu to add the checkbox column.
    * **Apply and Check the Box:** As you apply to jobs using the links in the sheet, simply check the box in the `Applied` column for that row.

3.  **Update Local Files for Analysis:** Once you are done applying for a session:
    * **Download from Sheets:** Download your current Google Sheet as a CSV file (`File > Download > Comma Separated Values (.csv)`).
    * **Archive the Old File:** If you have an existing `new_grad_swe_apply_links_applying.csv` file, rename it (e.g., to `applications_sept_2025.csv`) and move it into the `past_applied_data` folder.
    * **Name the New File:** Name the file you just downloaded exactly **`new_grad_swe_apply_links_applying.csv`** and place it in the main project folder.

4.  **Prepare Local File & Run Analysis:**
    * Prepare Tracker File: Run this to ensure your downloaded master file has the necessary Date Applied and Status columns for analysis.
        ```bash
        python prepare_tracker.py
        ```
    * Run the analysis script to see your updated, all-time statistics.
        ```bash
        python detailed_analysis.py
        ```
    * As you hear back from companies, update the **`Status`** column in your Google Sheet with values like `Interview`, `Offer`, etc., and then repeat Step 3 to see your new funnel metrics.

---
